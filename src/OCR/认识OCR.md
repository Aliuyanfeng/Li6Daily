---
date: 2025-11-07 09:46:11
title: 认识OCR
permalink: /pages/19c1ea
sidebarPrefix: OCR学习-
categories:
  - OCR
---


一些开源的OCR工具
- Tesseract
- PaddleOCR
- EasyOCR (基于Tesseract的Java版本，4.X 之后不再开源及免费提供)
- CNOCR

传统OCR 的通用原理

无论是哪一个 OCR 框架，它们的核心流程其实都包含三个阶段：

- 文本检测（Text Detection）
在图像中找到“哪里有文字”。
比如把一张发票图片分出一行一行、一块一块文字区域。

- 文本识别（Text Recognition）
对这些区域进行识别，把像素序列 → 字符序列。

- 后处理（Post Processing）
比如拼接、排序、去噪、纠错等，让输出更像自然语言。

本质上所有 OCR 引擎处理的都是 像素数组，无论你输入的是文件路径，还是numpy.ndarray，还是PIL.Image对象，最终都会转换为OCR引擎所能处理的像素数组。



# 对比说明
## Tesseract
Google 团队开源的一个较为传统的OCR识别工具，其基本的流程可以分为四个主要阶段  
``` text
图像预处理  →  文本行检测  →  字符识别  →  语言模型校正
```

Tesseract 使用 Leptonica 库读取以下格式之一的图像：PNG 、JPEG 、BMP 、GIF 、TIFF、PNM
原生不支持PDF类型文件
### 基本概述
图像预处理的目的是为了将图像转换为适合OCR识别的图像，如图像的增强、去噪、二值化、分割等。  
比如可能包括但不限于:
- 灰度化（Grayscale）：将彩色图片转为灰度, 举个例子就是把一张包含红、绿、蓝三种颜色通道（RGB）的彩色图片，转换为只有一个亮度通道的图像。灰度化通常是很多算法的前置步骤，因为很多计算机视觉任务只需要亮度信息，不需要颜色；

- 二值化（Binarization）：把图像转换成黑白两色，常用 Otsu 或 Sauvola 算法，二值化就像给你一把分界线：比这个亮度浅的都算“白纸”，比这亮度深的都算“黑字”。；

- 去噪与平滑（Denoising & Smoothing）：移除孤立像素；

- 倾斜校正（Deskewing）：检测文字的主方向，旋转到水平；

- 连通域分析（Connected Component Analysis）：查找相连的像素块，把它们分成一个个独立的区域。

- 版面分析（Page Segmentation）：区分文本、行、段落、横排还是竖排，顺序头区域。
  
- 文本行检测（Text Line Detection）：检测文字行。
  
- 字符分割（Character Segmentation）：把连在一起的黑块拆分成单个字符。
灰度化和二值化的质量直接影响分割是否准确，旧版本需要，新版本不需要

- 特征提取与识别：使用 LSTM（Long Short-Term Memory长短期记忆网络）或传统特征模板来识别字符。

### 革命性变化
**4.x版本是分水岭，比较核心的是更新了识别的引擎LSTM**
4.x之前的版本出现的问题是对于复杂的内容，倾斜、模糊、弯曲、多样化等，识别效果很差，4.x版本的LSTM引擎可以识别复杂的场景，识别效果大幅提升。
最主要的是引入的LSTM不再需要字符级的切割来识别，在以前的版本中 需要切割字符，然后再识别，而4.x版本的LSTM引擎可以直接识别整行内容，不需要切割字符。  
举例说明：  
假设输入图像是单行文字：  
`|---HELLO---|`  

在旧架构中，Tesseract 3.x 要这样：找出每个字母的边框；把它们切成 H、E、L、L、O；逐个识别。  
而在 LSTM 架构下：整行图像直接进入神经网络；神经网络网络逐步输出字符序列；最后自动对齐成 “HELLO”。

## Tesseract连通域类BFS过程（像素查找过程）

例子：
```text
. # . .
. # # .
. . # .
```
对应坐标图  

```text
(0,0) (0,1) (0,2) (0,3)
(1,0) (1,1) (1,2) (1,3)
(2,0) (2,1) (2,2) (2,3)
```

黑像素的位置  
```text
(0,1)
(1,1) (1,2)
      (2,2)
```

寻找像素流程：  
1. 从左上往右下扫描图像，遇到第一个黑像素：找到：(0,1) 给它编号 1：
```text
. 1 . .
. # # .
. . # .
```
2. 从 1 扩散 8 邻域,检查 (0,1) 周围的八个方向，先找到：(1,1) 是黑色 → 编号 2
```text
. 1 . .
. 2 # .
. . # .
```

```text
(0,1) 的邻域：
(-1,0)  越界（跳过）
(-1,1)  越界
(-1,2)  越界
(0,2)   是 '.' 不是黑
(1,2)   是 '#' → 暂存
(1,1)   是 '#' → 先加入
(1,0)   是 '.' 
(0,0)   是 '.'

```
3. 继续处理 1 的邻域 按照循序其次发现(1,2) 给编号 3
```text
. 1 . .
. 2 3 .
. . # .

```

4. 因为（0，1）编号1邻域已经处理完毕，轮到(1,1)编号2开始处理，查看 (1,1) 的 8 邻域
它会找到 (2,2) 这个最下面的黑像素 给编号 4：

```text

. 1 . .
. 2 3 .
. . 4 .

```
5. 处理编号3 的邻域，发现已经被处理过了，跳过
6. 处理编号4 的邻域，发现已经被处理过了，跳过
7. 至此，所有黑像素都被处理完毕，得到一个连通域集合：


📌 这个编号代表：

1 是第一个发现的黑点

2 是由 1 扩散出来的下一个

3 也是从 1 扩散到的

4 是从 2 扩散到的


## PaddleOCR

百度产品，很多兄弟产品

| 模型系列           | 核心任务             | 技术基础                 | 是否依赖语言模型 | 输出类型            | 代表用途           |
|------------------|:------------------:|:----------------------:|:---------------:|:-----------------:|:----------------:|
| **PP-OCRv5**       | 文字检测 + 识别      | CNN + CTC              | 否              | 文本               | 纯 OCR 提取       |
| **PP-StructureV3** | 版面分析、表格结构识别 | OCR + LayoutLM         | 否              | JSON / Markdown   | 文档结构还原       |
| **PaddleOCR-VL**   | 图文语义理解         | ViT + Transformer      | 是（轻量）        | 语义向量 / 答案     | 图文问答、语义检索 |
| **PP-ChatOCRv4**   | 文档问答、智能摘要     | OCR-VL + LLM（如 ERNIE） | 是（强依赖）      | 问答 / 结构化语义    | 智能文档对话       |


PaddleOCR 仅支持以“jpg”、“png”、“jpeg”、“bmp”、“pdf”为后缀的 PDF 和图像文件  


PaddleOCR 把 OCR 流程拆成几个模块，每个模块对应一个模型或者任务：

| 模块          | 对应模型                             | 主要功能                          |
| ----------- | -------------------------------- | ----------------------------- |
| **文档方向分类**  | `doc_orientation_classify_model` | 判断文档是否旋转，输出旋转角度（0/90/180/270） |
| **文档扭曲矫正**  | `doc_unwarping_model`            | 对扫描文档或拍照文档进行透视/折叠矫正           |
| **文字检测**    | `text_detection_model`           | 在图片上检测出每个文字区域（bounding box）   |
| **文本行方向分类** | `textline_orientation_model`     | 判断每行文字方向（水平/垂直）               |
| **文字识别**    | `text_recognition_model`         | 将文字区域转换成文字内容（OCR 核心）          |


这些模型本身是AI模型，经过预训练，可以直接拿来用，如果不符合预期，可以通过微调的方式进行优化。