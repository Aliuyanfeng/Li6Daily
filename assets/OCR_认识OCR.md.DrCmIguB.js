import{_ as s,c as e,o as n,aN as t}from"./chunks/framework.CuNGkOej.js";const u=JSON.parse('{"title":"认识OCR","description":"","frontmatter":{"date":"2025-11-07T09:46:11.000Z","title":"认识OCR","permalink":"/pages/19c1ea","sidebarPrefix":"OCR学习-","categories":["OCR"]},"headers":[],"relativePath":"OCR/认识OCR.md","filePath":"OCR/认识OCR.md","lastUpdated":1763519887000}'),l={name:"OCR/认识OCR.md"};function p(i,a,r,d,c,o){return n(),e("div",null,[...a[0]||(a[0]=[t(`<h1 id="认识ocr" tabindex="-1">认识OCR <a class="header-anchor" href="#认识ocr" aria-label="Permalink to &quot;认识OCR&quot;">​</a></h1><p>一些开源的OCR工具</p><ul><li>Tesseract</li><li>PaddleOCR</li><li>EasyOCR (基于Tesseract的Java版本，4.X 之后不再开源及免费提供)</li><li>CNOCR</li></ul><p>传统OCR 的通用原理</p><p>无论是哪一个 OCR 框架，它们的核心流程其实都包含三个阶段：</p><ul><li><p>文本检测（Text Detection） 在图像中找到“哪里有文字”。 比如把一张发票图片分出一行一行、一块一块文字区域。</p></li><li><p>文本识别（Text Recognition） 对这些区域进行识别，把像素序列 → 字符序列。</p></li><li><p>后处理（Post Processing） 比如拼接、排序、去噪、纠错等，让输出更像自然语言。</p></li></ul><p>本质上所有 OCR 引擎处理的都是 像素数组，无论你输入的是文件路径，还是numpy.ndarray，还是PIL.Image对象，最终都会转换为OCR引擎所能处理的像素数组。</p><h1 id="对比说明" tabindex="-1">对比说明 <a class="header-anchor" href="#对比说明" aria-label="Permalink to &quot;对比说明&quot;">​</a></h1><h2 id="tesseract" tabindex="-1">Tesseract <a class="header-anchor" href="#tesseract" aria-label="Permalink to &quot;Tesseract&quot;">​</a></h2><p>Google 团队开源的一个较为传统的OCR识别工具，其基本的流程可以分为四个主要阶段</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>图像预处理  →  文本行检测  →  字符识别  →  语言模型校正</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>Tesseract 使用 Leptonica 库读取以下格式之一的图像：PNG 、JPEG 、BMP 、GIF 、TIFF、PNM 原生不支持PDF类型文件</p><h3 id="基本概述" tabindex="-1">基本概述 <a class="header-anchor" href="#基本概述" aria-label="Permalink to &quot;基本概述&quot;">​</a></h3><p>图像预处理的目的是为了将图像转换为适合OCR识别的图像，如图像的增强、去噪、二值化、分割等。<br> 比如可能包括但不限于:</p><ul><li><p>灰度化（Grayscale）：将彩色图片转为灰度, 举个例子就是把一张包含红、绿、蓝三种颜色通道（RGB）的彩色图片，转换为只有一个亮度通道的图像。灰度化通常是很多算法的前置步骤，因为很多计算机视觉任务只需要亮度信息，不需要颜色；</p></li><li><p>二值化（Binarization）：把图像转换成黑白两色，常用 Otsu 或 Sauvola 算法，二值化就像给你一把分界线：比这个亮度浅的都算“白纸”，比这亮度深的都算“黑字”。；</p></li><li><p>去噪与平滑（Denoising &amp; Smoothing）：移除孤立像素；</p></li><li><p>倾斜校正（Deskewing）：检测文字的主方向，旋转到水平；</p></li><li><p>连通域分析（Connected Component Analysis）：查找相连的像素块，把它们分成一个个独立的区域。</p></li><li><p>版面分析（Page Segmentation）：区分文本、行、段落、横排还是竖排，顺序头区域。</p></li><li><p>文本行检测（Text Line Detection）：检测文字行。</p></li><li><p>字符分割（Character Segmentation）：把连在一起的黑块拆分成单个字符。 灰度化和二值化的质量直接影响分割是否准确，旧版本需要，新版本不需要</p></li><li><p>特征提取与识别：使用 LSTM（Long Short-Term Memory长短期记忆网络）或传统特征模板来识别字符。</p></li></ul><h3 id="革命性变化" tabindex="-1">革命性变化 <a class="header-anchor" href="#革命性变化" aria-label="Permalink to &quot;革命性变化&quot;">​</a></h3><p><strong>4.x版本是分水岭，比较核心的是更新了识别的引擎LSTM</strong> 4.x之前的版本出现的问题是对于复杂的内容，倾斜、模糊、弯曲、多样化等，识别效果很差，4.x版本的LSTM引擎可以识别复杂的场景，识别效果大幅提升。 最主要的是引入的LSTM不再需要字符级的切割来识别，在以前的版本中 需要切割字符，然后再识别，而4.x版本的LSTM引擎可以直接识别整行内容，不需要切割字符。<br> 举例说明：<br> 假设输入图像是单行文字：<br><code>|---HELLO---|</code></p><p>在旧架构中，Tesseract 3.x 要这样：找出每个字母的边框；把它们切成 H、E、L、L、O；逐个识别。<br> 而在 LSTM 架构下：整行图像直接进入神经网络；神经网络网络逐步输出字符序列；最后自动对齐成 “HELLO”。</p><h2 id="tesseract连通域类bfs过程-像素查找过程" tabindex="-1">Tesseract连通域类BFS过程（像素查找过程） <a class="header-anchor" href="#tesseract连通域类bfs过程-像素查找过程" aria-label="Permalink to &quot;Tesseract连通域类BFS过程（像素查找过程）&quot;">​</a></h2><p>例子：</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>. # . .</span></span>
<span class="line"><span>. # # .</span></span>
<span class="line"><span>. . # .</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>对应坐标图</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(0,0) (0,1) (0,2) (0,3)</span></span>
<span class="line"><span>(1,0) (1,1) (1,2) (1,3)</span></span>
<span class="line"><span>(2,0) (2,1) (2,2) (2,3)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>黑像素的位置</p><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(0,1)</span></span>
<span class="line"><span>(1,1) (1,2)</span></span>
<span class="line"><span>      (2,2)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>寻找像素流程：</p><ol><li>从左上往右下扫描图像，遇到第一个黑像素：找到：(0,1) 给它编号 1：</li></ol><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>. 1 . .</span></span>
<span class="line"><span>. # # .</span></span>
<span class="line"><span>. . # .</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ol start="2"><li>从 1 扩散 8 邻域,检查 (0,1) 周围的八个方向，先找到：(1,1) 是黑色 → 编号 2</li></ol><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>. 1 . .</span></span>
<span class="line"><span>. 2 # .</span></span>
<span class="line"><span>. . # .</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>(0,1) 的邻域：</span></span>
<span class="line"><span>(-1,0)  越界（跳过）</span></span>
<span class="line"><span>(-1,1)  越界</span></span>
<span class="line"><span>(-1,2)  越界</span></span>
<span class="line"><span>(0,2)   是 &#39;.&#39; 不是黑</span></span>
<span class="line"><span>(1,2)   是 &#39;#&#39; → 暂存</span></span>
<span class="line"><span>(1,1)   是 &#39;#&#39; → 先加入</span></span>
<span class="line"><span>(1,0)   是 &#39;.&#39; </span></span>
<span class="line"><span>(0,0)   是 &#39;.&#39;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><ol start="3"><li>继续处理 1 的邻域 按照循序其次发现(1,2) 给编号 3</li></ol><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>. 1 . .</span></span>
<span class="line"><span>. 2 3 .</span></span>
<span class="line"><span>. . # .</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><ol start="4"><li>因为（0，1）编号1邻域已经处理完毕，轮到(1,1)编号2开始处理，查看 (1,1) 的 8 邻域 它会找到 (2,2) 这个最下面的黑像素 给编号 4：</li></ol><div class="language-text vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span></span></span>
<span class="line"><span>. 1 . .</span></span>
<span class="line"><span>. 2 3 .</span></span>
<span class="line"><span>. . 4 .</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><ol start="5"><li>处理编号3 的邻域，发现已经被处理过了，跳过</li><li>处理编号4 的邻域，发现已经被处理过了，跳过</li><li>至此，所有黑像素都被处理完毕，得到一个连通域集合：</li></ol><p>📌 这个编号代表：</p><p>1 是第一个发现的黑点</p><p>2 是由 1 扩散出来的下一个</p><p>3 也是从 1 扩散到的</p><p>4 是从 2 扩散到的</p><h2 id="paddleocr" tabindex="-1">PaddleOCR <a class="header-anchor" href="#paddleocr" aria-label="Permalink to &quot;PaddleOCR&quot;">​</a></h2><p>百度产品，很多兄弟产品</p><table tabindex="0"><thead><tr><th>模型系列</th><th style="text-align:center;">核心任务</th><th style="text-align:center;">技术基础</th><th style="text-align:center;">是否依赖语言模型</th><th style="text-align:center;">输出类型</th><th style="text-align:center;">代表用途</th></tr></thead><tbody><tr><td><strong>PP-OCRv5</strong></td><td style="text-align:center;">文字检测 + 识别</td><td style="text-align:center;">CNN + CTC</td><td style="text-align:center;">否</td><td style="text-align:center;">文本</td><td style="text-align:center;">纯 OCR 提取</td></tr><tr><td><strong>PP-StructureV3</strong></td><td style="text-align:center;">版面分析、表格结构识别</td><td style="text-align:center;">OCR + LayoutLM</td><td style="text-align:center;">否</td><td style="text-align:center;">JSON / Markdown</td><td style="text-align:center;">文档结构还原</td></tr><tr><td><strong>PaddleOCR-VL</strong></td><td style="text-align:center;">图文语义理解</td><td style="text-align:center;">ViT + Transformer</td><td style="text-align:center;">是（轻量）</td><td style="text-align:center;">语义向量 / 答案</td><td style="text-align:center;">图文问答、语义检索</td></tr><tr><td><strong>PP-ChatOCRv4</strong></td><td style="text-align:center;">文档问答、智能摘要</td><td style="text-align:center;">OCR-VL + LLM（如 ERNIE）</td><td style="text-align:center;">是（强依赖）</td><td style="text-align:center;">问答 / 结构化语义</td><td style="text-align:center;">智能文档对话</td></tr></tbody></table><p>PaddleOCR 仅支持以“jpg”、“png”、“jpeg”、“bmp”、“pdf”为后缀的 PDF 和图像文件</p><p>PaddleOCR 把 OCR 流程拆成几个模块，每个模块对应一个模型或者任务：</p><table tabindex="0"><thead><tr><th>模块</th><th>对应模型</th><th>主要功能</th></tr></thead><tbody><tr><td><strong>文档方向分类</strong></td><td><code>doc_orientation_classify_model</code></td><td>判断文档是否旋转，输出旋转角度（0/90/180/270）</td></tr><tr><td><strong>文档扭曲矫正</strong></td><td><code>doc_unwarping_model</code></td><td>对扫描文档或拍照文档进行透视/折叠矫正</td></tr><tr><td><strong>文字检测</strong></td><td><code>text_detection_model</code></td><td>在图片上检测出每个文字区域（bounding box）</td></tr><tr><td><strong>文本行方向分类</strong></td><td><code>textline_orientation_model</code></td><td>判断每行文字方向（水平/垂直）</td></tr><tr><td><strong>文字识别</strong></td><td><code>text_recognition_model</code></td><td>将文字区域转换成文字内容（OCR 核心）</td></tr></tbody></table><p>这些模型本身是AI模型，经过预训练，可以直接拿来用，如果不符合预期，可以通过微调的方式进行优化。</p>`,48)])])}const h=s(l,[["render",p]]);export{u as __pageData,h as default};
